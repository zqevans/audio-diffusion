
[DEFAULTS]

#name of the run
name = test-dvae

# training data directory
training_dir = /home/ubuntu/datasets/SignalTrain_LA2A_Dataset_1.1

# the batch size
batch_size = 8 

# number of GPUs to use for training
num_gpus = 1 

# number of nodes to use for training
num_nodes = 1 

# number of CPU workers for the DataLoader
num_workers = 12

# Number of samples to train on must be a multiple of 16384
sample_size = 32768 

# Number of epochs between demos
demo_every = 50 

# Number of denoising steps for the demos       
demo_steps = 250

# Number of demos to create
num_demos = 16

# the random seed
seed = 42

# Batches for gradient accumulation
accum_batches = 2

# The sample rate of the audio
sample_rate = 48000   

# Number of steps between checkpoints
checkpoint_every = 10000                              

# the EMA decay
ema_decay = 0.995                           

#Encoder params
encoder_depth = 4
encoder_n_attn_layers = 2
encoder_c_mults = [512, 512, 1024,1024]

#Decoder params
decoder_depth = 14
decoder_n_attn_layers = 6
decoder_c_mults = [128, 128, 256, 256] + [512] * 10

# the validation set
latent_dim = 32              

# the validation set
codebook_size = 1024                 

# number of quantizers
num_quantizers = 0           

# number of heads for the memcodes
num_heads = 8

# If true training data is kept in RAM
cache_training_data = False  

# number of sub-bands for the PQMF filter
pqmf_bands = 1

# randomly crop input audio? (for augmentation)
random_crop = True 

# normalize input audio?
norm_inputs = False

#Number of steps before freezing encoder in dVAE
warmup_steps = 100000

# for jukebox imbeddings. 0 (high res), 1 (med), or 2 (low res)
jukebox_layer = 0

# If true, use MFCCs instead of spectrograms for training
use_mfcc = True

# checkpoint file to (re)start training from
ckpt_path = ''

# configuration model specifying model hyperparameters
model_config = ''