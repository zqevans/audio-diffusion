
[DEFAULTS]

#name of the run
name = test-vocoder

# training data directory
training_dir = /home/ubuntu/datasets/SignalTrain_LA2A_Dataset_1.1

# the batch size
batch_size = 8 

# number of GPUs to use for training
num_gpus = 1 

# number of nodes to use for training
num_nodes = 1 

# number of CPU workers for the DataLoader
num_workers = 12

# Number of audio samples for the training input
sample_size = 65536 

# Number of epochs between demos
demo_every = 20 

# Number of denoising steps for the demos       
demo_steps = 250

# Number of demos to create
num_demos = 16

# the random seed
seed = 42

# Batches for gradient accumulation
accum_batches = 1

# The sample rate of the audio
sample_rate = 48000   

# Number of steps between checkpoints
checkpoint_every = 10000                              

# the EMA decay
ema_decay = 0.995                           

use_mfcc = False

n_fft = 1024

hop_length = 256

n_mels = 80

# If true training data is kept in RAM
cache_training_data = False  

# randomly crop input audio? (for augmentation)
random_crop = True 

# checkpoint file to (re)start training from
ckpt_path = ''

# configuration model specifying model hyperparameters
model_config = ''

#the multiprocessing start method ['fork', 'forkserver', 'spawn']
start_method = 'forkserver'